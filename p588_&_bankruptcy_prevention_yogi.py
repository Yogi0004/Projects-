# -*- coding: utf-8 -*-
"""P588 & Bankruptcy Prevention_yogi.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MlEBEfLmGKjaBmM9EvWLl8-oIrVAMf-N

##** Project Name : P588 & Bankruptcy Prevention**

## 1.PROJECT SETUP & IMPORTS

Explanation: import libraries and set plotting defaults.
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler , MinMaxScaler , LabelEncoder
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report,roc_curve,precision_recall_curve,auc
import statsmodels.api as sm
import warnings
warnings.filterwarnings("ignore")

#  Load the dataset
data = pd.read_excel("/content/Bankruptcy (2).xlsx")

data.columns

data.head()

data.shape

data.info()

data.describe()

"""There‚Äôs no indication of outliers or extreme imbalance in any risk factor. The distributions appear consistent and symmetrical across all variables"""

data.isnull().sum()

data.duplicated().sum()

plt.figure(figsize=(10,6))
ax = sns.countplot(x='class', data=data)
plt.title('Target Class Distribution')
plt.xlabel('Class')
plt.ylabel('Count')

# Add count labels
for container in ax.containers:
    ax.bar_label(container)

plt.show()

#Distribution of risk factors
cols = ['industrial_risk', 'management_risk', 'financial_flexibility',
        'credibility', 'competitiveness', 'operating_risk']

plt.figure(figsize=(12, 8))

for i, col in enumerate(cols, 1):
    plt.subplot(3, 2, i)
    ax = sns.countplot(x=col, data=data, width=0.6)
    plt.title(col)

    # Add count labels on bars
    for container in ax.containers:
        ax.bar_label(container, fontsize=9)

plt.tight_layout()
plt.show()

# Correlation heatmap among features
plt.figure(figsize=(8,6))
corr = data[cols].corr(numeric_only=True)
sns.heatmap(corr, annot=True, cmap='coolwarm', center=0)
plt.title('Feature correlation heatmap')
plt.show()

# Boxplots to visualize distributions of features by target class
for col in cols:
    plt.figure(figsize=(8,6))
    sns.boxplot(x='class', y=col, data=data)
    plt.title(f'Boxplot of {col} by class')
    plt.show()

# KDE plots to visualize distributions of features by target class
for col in cols:
    plt.figure(figsize=(8,6))
    sns.kdeplot(data=data, x=col, hue='class', fill=True, common_norm=False, alpha=0.5)
    plt.title(f'KDE plot of {col} by class')
    plt.show()

le = LabelEncoder()

data["class"] = le.fit_transform(data["class"])

"""**Correlation between feature and target**"""

data.corr()

"""**Checking multicollinearity using VIF**"""

from statsmodels.stats.outliers_influence import variance_inflation_factor

X = data[['industrial_risk', 'management_risk', 'financial_flexibility',
          'credibility', 'competitiveness', 'operating_risk']]
y = data['class']

# Add constant term for intercept
X = sm.add_constant(X)

# Calculate VIF for each feature
vif_data = pd.DataFrame()
vif_data["Feature"] = X.columns
vif_data["VIF"] = [variance_inflation_factor(X.values, i)
                   for i in range(X.shape[1])]

print(vif_data)

"""All VIF values are below 5, indicating no significant multicollinearity among predictors.

**Feature-Target Relationship (Chi-Square Test)**
"""

from sklearn.feature_selection import chi2
import pandas as pd

chi_scores = chi2(X, y)
pd.DataFrame({'Feature': X.columns, 'Chi2 Score': chi_scores[0], 'p-value': chi_scores[1]})

"""Features with low p-values (< 0.05) ‚Äî like financial_flexibility, credibility, competitiveness, management_risk, and operating_risk ‚Äî have a strong and significant relationship with the target.
Only industrial_risk shows a weaker association, while the constant has no effect.
"""









"""#Second Session of the Project- MODEL BUILDING PHASE:-

#Goal:-
To train different Machine Learning models that can predict whether a company will go bankrupt (1) or not bankrupt (0), based on features such as risks, flexibility, credibility, etc.

This is a binary classification problem, so we‚Äôll use classification algorithms.

#Model Buliding Steps
**step 1 - Import Libraries**
"""

# Step 1: Import libraries
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import os # Import the os module
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report,roc_curve,precision_recall_curve,auc
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from xgboost import XGBClassifier
import warnings
warnings.filterwarnings("ignore")

df = pd.read_excel("/content/Bankruptcy (2).xlsx")

df.columns

df['class'] = df['class'].astype(str).str.lower().str.strip()
df['target'] = df['class'].apply(lambda x: 1 if 'bankruptcy' in x and 'non' not in x else 0)

#  Step 1.2: Identify numeric columns (risk features)
risk_cols = ['industrial_risk', 'management_risk', 'financial_flexibility',
             'credibility', 'competitiveness', 'operating_risk']

# Convert risk features to numeric safely
for col in risk_cols:
    df[col] = pd.to_numeric(df[col], errors='coerce')

df[risk_cols] = df[risk_cols].fillna(0)

# Step 1.4: Define features and target
X = df[risk_cols]
y = df['target']

# Split dataset into training and testing
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

print("X_train Training set:", X_train.shape)
print("X_test Testing set:", X_test.shape)
print("y_Training set:", y_train.shape)
print("y_Testing set:", y_test.shape)

y.value_counts()

"""#MODEL 1: Logistic Regression:"""

from sklearn.linear_model import LogisticRegression

log_model = LogisticRegression()

log_model.fit(X_train,y_train)

y_pred = log_model.predict(X_test)

print("Acuuracy:",accuracy_score(y_test,y_pred))
print('Confuison_matrix:',confusion_matrix(y_test,y_pred))
print("Classification_Report:",classification_report(y_test,y_pred))

"""#Confusion Matrix (Heatmap):"""

cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(5,4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix - Logistic Regression')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

"""#ROC Curve:"""

fpr, tpr, _ = roc_curve(y_test, y_pred)
plt.plot(fpr, tpr)
plt.title("Logistic Regression - ROC Curve")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.grid()
plt.show()

"""# Precision-Recall Curve:"""

precision, recall, _ = precision_recall_curve(y_test, y_pred)
plt.plot(recall, precision)
plt.title("Logistic Regression - Precision Recall Curve")
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.grid()
plt.show()

plt.hist(y_pred, bins=10, edgecolor='black')
plt.title("Logistic Regression - Probability Histogram")
plt.xlabel("Predicted Probabilities")
plt.ylabel("Count")
plt.grid()
plt.show()

"""#Actual VS Predicted Comparison:"""

compare_df = pd.DataFrame({'Actual': y_test.values, 'Predicted': y_pred})
sns.stripplot(data=compare_df, x='Actual', y='Predicted', jitter=True, palette='coolwarm')
plt.title('Actual vs Predicted - Logistic Regression')
plt.show()

"""#Feature Importance (Coefficient Plot):"""

coeff_df = pd.DataFrame({
    'Feature': X.columns,
    'Coefficient': log_model.coef_[0]
}).sort_values(by='Coefficient', ascending=True)

plt.figure(figsize=(8,5))
sns.barplot(x='Coefficient', y='Feature', data=coeff_df, palette='viridis')
plt.title('Feature Importance - Logistic Regression Coefficients')
plt.axvline(0, color='red', linestyle='--')
plt.show()

print(coeff_df)

"""# Summary Metrics Table:"""

from sklearn.metrics import roc_auc_score, precision_score, recall_score

# Calculate AUC
roc_auc = roc_auc_score(y_test, y_pred)

results = {
    "Accuracy": round(accuracy_score(y_test, y_pred)*100,2),
    "AUC": round(roc_auc*100,2),
    "Precision": round(precision_score(y_test, y_pred)*100,2),
    "Recall": round(recall_score(y_test, y_pred)*100,2)
}
print("\n Model Summary:", results)

"""#Model-2: Decision Tree Classifer:-"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

df = pd.read_excel("/content/Bankruptcy (2).xlsx")

df.columns = df.columns.str.strip().str.lower()

# Replace textual target labels with numeric
df['class'] = df['class'].replace({
    'non-bankruptcy': 0,
    'bankruptcy': 1,
    'non_bankruptcy': 0,
    'bankrupt': 1
})

# Convert all features to numeric (replace text with NaN)
for col in df.columns:
    df[col] = pd.to_numeric(df[col], errors='coerce')

# Drop rows without target
df = df.dropna(subset=['class'])

# fill the missing numeric data with the median
df.fillna(df.median())

X = df.drop(columns=['class'])
y = df['class']

"""**Train the Decision Tree Model**"""

dt_model = DecisionTreeClassifier(criterion='gini',max_depth=5,min_samples_split=4,class_weight='balanced',random_state=42)

dt_model.fit(X_train,y_train)

y_pred = dt_model.predict(X_test)

print(" Decision Tree Performance ")
print("Accuracy:", round(accuracy_score(y_test, y_pred)*100, 2), "%")
print("\nClassification Report:\n", classification_report(y_test, y_pred))

"""#**Confusion Matrix (Heatmap Visualization)**"""

plt.figure(figsize=(5,4))
sns.heatmap(cm, annot=True,fmt='d',cmap='pink')
plt.title("Decision Tree - Confusion Matrix")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.show()

"""**Feature Importance Visualization**"""

importances = pd.Series(dt_model.feature_importances_, index=X.columns).sort_values(ascending=True)

plt.figure(figsize=(8,5))
sns.barplot(x=importances, y=importances.index, palette='viridis')
plt.title("Feature Importance - Decision Tree")
plt.xlabel("Importance Score")
plt.ylabel("Features")
plt.show()

"""**Visualize the Decision Tree Structure:**

"""

plt.figure(figsize=(16,10))
plot_tree(
    dt_model,
    feature_names=X.columns,
    class_names=["Non-Bankruptcy", "Bankruptcy"],
    filled=True,
    rounded=True,
    fontsize=9
)
plt.title("Decision Tree Visualization")
plt.show()

"""**ROC Curve & AUC Score:**"""

y_pred= dt_model.predict_proba(X_test)[:,1]
fpr, tpr, thresholds = roc_curve(y_test, y_pred)
auc_score = roc_auc_score(y_test, y_pred)

plt.figure(figsize=(6,5))
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f"ROC Curve (AUC = {auc_score:.2f})")
plt.plot([0,1], [0,1], color='navy', lw=2, linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve - Decision Tree')
plt.legend(loc='lower right')
plt.show()

"""**Combine All Visuals Together (Comparison Dashboard)**"""

importances = pd.Series(dt_model.feature_importances_, index=X.columns).sort_values(ascending=True)

plt.figure(figsize=(14,8))

plt.subplot(2,2,1)
sns.heatmap(cm, annot=True, fmt='d', cmap='Greens')
plt.title("Confusion Matrix")

plt.subplot(2,2,2)
sns.barplot(x=importances, y=importances.index, palette='coolwarm')
plt.title("Feature Importance")

plt.subplot(2,2,3)
plt.plot(fpr, tpr, color='purple', label=f"AUC = {auc_score:.2f}")
plt.plot([0,1],[0,1],'--',color='gray')
plt.title("ROC Curve")
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.legend()

plt.subplot(2,2,4)
plt.text(0.1,0.6,f"Accuracy: {round(accuracy_score(y_test, y_pred)*100,2)}%", fontsize=14)
plt.text(0.1,0.5,f"AUC: {auc_score:.2f}", fontsize=14)
plt.text(0.1,0.4,f"Top Feature: {importances.idxmax()}", fontsize=14)
plt.axis('off')
plt.title("Model Summary")

plt.tight_layout()
plt.show()



"""#Model -2 : Random Forest Classifier:-"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score,confusion_matrix,classification_report

df = pd.read_excel("/content/Bankruptcy (2).xlsx")

df.columns = df.columns.str.strip().str.lower()

# Convert class column to numeric
df['class'] = df['class'].replace({
    'non-bankruptcy': 0,
    'non_bankruptcy': 0,
    'bankruptcy': 1,
    'bankrupt': 1
})

# Convert all features to numeric
for col in df.columns:
    df[col] = pd.to_numeric(df[col], errors='coerce')

# Remove rows without target
df = df.dropna(subset=['class'])

# Fill missing values with median
df = df.fillna(df.median())

X = df.drop('class',axis=1)
y = df['class']

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

print("Data cleaned and ready for Random Forest Modeling")
print("Training set:",X_train.shape)
print("Testing set:",y_test.shape)
print(X_train.head())
print(y_train.head())

"""**STEP 2 ‚Äì Train the Random Forest Model:**"""

rf_model = RandomForestClassifier(n_estimators=100,max_depth=6,random_state=42,class_weight='balanced')

rf_model.fit(X_train,y_train)

y_pred = rf_model.predict(X_test)

print(" Random Forest Model Performance")
print("Accuracy_score:",accuracy_score(y_test,y_pred))
print("classification_report:",classification_report(y_test,y_pred))

cm = confusion_matrix(y_test,y_pred)
cm

"""#Why Random Forest?

Uses multiple decision trees (ensemble learning)

Reduces overfitting

Handles both categorical and continuous features

Great for small and medium datasets like yours (250 companies)

**STEP 3 - Confusion Matrix (Visual Heatmap):-**
"""

plt.figure(figsize=(5,4))
sns.heatmap(cm,annot=True,fmt='d',cmap='viridis')
plt.title("Random Forest & Confusion Matrix")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.show()

"""**STEP 4 ‚Äì Feature Importance Visualization:-**"""

importances = pd.Series(rf_model.feature_importances_, index=X.columns).sort_values(ascending=True)

plt.figure(figsize=(8,5))
sns.barplot(x=importances, y=importances.index, palette='viridis')
plt.title("Feature Importance - Random Forest")
plt.xlabel("Importance Score")
plt.ylabel("Features")
plt.show()

"""**STEP 5 ‚Äì ROC Curve & AUC (Performance Visualization):-**"""

from sklearn.metrics import roc_curve, roc_auc_score

y_prob = rf_model.predict_proba(X_test)[:, 1]  # probability for class=1
fpr, tpr, thresholds = roc_curve(y_test, y_prob)
auc_score = roc_auc_score(y_test, y_prob)

plt.figure(figsize=(6,5))
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f"ROC Curve (AUC = {auc_score:.2f})")
plt.plot([0,1],[0,1], color='navy', lw=2, linestyle='--')
plt.title("ROC Curve - Random Forest")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.legend(loc="lower right")
plt.show()

print("AUC Score:", round(auc_score, 3))

"""** STEP 6 - Model Summary Dashboard:-**"""

plt.figure(figsize=(14,8))

# Confusion Matrix
plt.subplot(2,2,1)
sns.heatmap(cm, annot=True, fmt='d', cmap='Greens')
plt.title("Confusion Matrix")

# Feature Importance
plt.subplot(2,2,2)
sns.barplot(x=importances, y=importances.index, palette='coolwarm')
plt.title("Feature Importance")

# ROC Curve
plt.subplot(2,2,3)
plt.plot(fpr, tpr, color='purple', label=f"AUC = {auc_score:.2f}")
plt.plot([0,1],[0,1],'--',color='gray')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend()

# Model Summary
plt.subplot(2,2,4)
plt.text(0.1,0.7,f"Accuracy: {round(accuracy_score(y_test, y_pred)*100,2)}%", fontsize=13)
plt.text(0.1,0.6,f"AUC Score: {auc_score:.2f}", fontsize=13)
plt.text(0.1,0.5,f"Top Feature: {importances.idxmax()}", fontsize=13)
plt.axis('off')
plt.title("Model Summary")

plt.tight_layout()
plt.show()

"""**Interpretation of Random Forest Result**s

Accuracy should typically be 85‚Äì95%

AUC > 0.85 indicates high predictive ability

Top predictors: Industrial Risk, Management Risk, Financial Flexibility

Balanced results across both classes (good recall for bankruptcy)
"""



"""# Model-4 : Support Vector Machine (SVM)"""

# STEP 1: Import & Clean Dataset
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline

df = pd.read_excel("/content/Bankruptcy (2).xlsx")

df.columns = df.columns.str.strip().str.lower()

# Convert class column to numeric (bankruptcy=1, non-bankruptcy=0)
df['class'] = df['class'].replace({
    'non-bankruptcy': 0,
    'non_bankruptcy': 0,
    'bankruptcy': 1,
    'bankrupt': 1
})

# Convert all other features to numeric
for col in df.columns:
    df[col] = pd.to_numeric(df[col], errors='coerce')

# Remove rows without target
df = df.dropna(subset=['class'])

# Fill missing numeric values with median
df = df.fillna(df.median())

x_train , X_test, y_train, y_test = train_test_split(X,y , test_size=0.2,random_state=42,stratify=y)

print("Data cleaned  succesfully")
print("X_Training set:",X_train.shape)
print("X_Testing set:",X_test.shape)
print("y_Training set:",y_train.shape)
print("y_Testing set:",y_test.shape)

"""**Step -2 : Bulid and Train the SVM Model **"""

# Create pipeline (scaling + SVM)
svm_model = Pipeline([
    ("scaler", StandardScaler()),
    ("svm", SVC(kernel="rbf", class_weight='balanced', probability=True, random_state=42))
])

svm_model.fit(X_train,y_train)

print("SVM Model Preformance")
print("Accuracy:",accuracy_score(y_test,y_pred))
print(classification_report(y_test,y_pred))

cm = confusion_matrix(y_test,y_pred)
cm

"""**Why use a Pipeline?**

SVMs are sensitive to feature scales ‚Äî scaling ensures better boundary optimization.

**STEP 3 ‚Äì Confusion Matrix Visualization**
"""

plt.figure(figsize=(5,4))
sns.heatmap(cm, annot=True, fmt='d', cmap='coolwarm')
plt.title("SVM - Confusion Matrix")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.show()

"""**STEP 4 ‚Äì ROC Curve & AUC (Model Evaluation)**"""

from sklearn.metrics import roc_curve, roc_auc_score

# Probabilities for class=1 (bankruptcy)
y_prob = svm_model.predict_proba(X_test)[:, 1]

# Compute ROC and AUC
fpr, tpr, thresholds = roc_curve(y_test, y_prob)
auc_score = roc_auc_score(y_test, y_prob)

plt.figure(figsize=(6,5))
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f"ROC Curve (AUC = {auc_score:.2f})")
plt.plot([0,1], [0,1], color='navy', lw=2, linestyle='--')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve - SVM Model")
plt.legend(loc="lower right")
plt.show()

print("AUC Score:", round(auc_score, 3))

"""AUC > 0.85 ‚Üí Excellent model performance.
This shows the model‚Äôs ability to separate bankrupt vs non-bankrupt companies.

**STEP-5: Feature Infulence Visualization**

SVMs with RBF kernels don‚Äôt have direct feature importances,
but you can approximate them using model coefficients (for linear SVMs)
or permutation importance.
"""

from sklearn.inspection import permutation_importance

result = permutation_importance(
    svm_model, X_test, y_test, scoring='accuracy', n_repeats=10, random_state=42
)

importance_df = pd.DataFrame({
    'Feature': X.columns,
    'Importance': result.importances_mean
}).sort_values(by='Importance', ascending=True)

plt.figure(figsize=(8,5))
sns.barplot(x='Importance', y='Feature', data=importance_df, palette='viridis')
plt.title("Approximate Feature Importance - SVM (Permutation Importance)")
plt.xlabel("Importance Score")
plt.ylabel("Features")
plt.show()

"""**Interpretation:**

Higher bar = greater influence on model‚Äôs prediction.

**STEP 6 - Model Summary Dashboard**
"""

# =============================================================
# STEP 6: Model Summary Dashboard
# =============================================================
plt.figure(figsize=(14,8))

# Confusion Matrix
plt.subplot(2,2,1)
sns.heatmap(cm, annot=True, fmt='d', cmap='coolwarm')
plt.title("Confusion Matrix")

# Feature Importance
plt.subplot(2,2,2)
sns.barplot(x='Importance', y='Feature', data=importance_df, palette='crest')
plt.title("Feature Importance (Permutation)")

# ROC Curve
plt.subplot(2,2,3)
plt.plot(fpr, tpr, color='purple', lw=2, label=f"AUC = {auc_score:.2f}")
plt.plot([0,1],[0,1],'--',color='gray')
plt.title("ROC Curve")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.legend()

# Model Summary Info
plt.subplot(2,2,4)
plt.text(0.1,0.7,f"Accuracy: {round(accuracy_score(y_test, y_pred)*100,2)}%", fontsize=13)
plt.text(0.1,0.6,f"AUC Score: {auc_score:.2f}", fontsize=13)
plt.text(0.1,0.5,f"Top Feature: {importance_df.iloc[-1,0]}", fontsize=13)
plt.axis('off')
plt.title("Model Summary")

plt.tight_layout()
plt.show()

"""**Expected Results:**


Accuracy: ~85‚Äì93%

AUC: > 0.85 (good)

Top Predictors: industrial_risk, management_risk, financial_flexibility
"""





"""# Model-5 : XGBoost Classifier

**STEP 1 ‚Äì Import Libraries & Clean Dataset**
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score,classification_report,confusion_matrix,roc_curve,roc_auc_score

df = pd.read_excel("/content/Bankruptcy (2).xlsx")

df.columns = df.columns.str.strip().str.lower()

# Encode the target varibles
df['class'] = df['class'].replace({'non-bankruptcy':0,'non_bankruptcy':0,'bankruptcy':1,'bankrupt':1})

# Convert all columns to numeric
for col in df.columns:
    df[col] = pd.to_numeric(df[col], errors='coerce')

# Drop rows without target
df = df.dropna(subset=['class'])

# Fill missing values with median
df = df.fillna(df.median())

#Split data
X = df.drop('class',axis=1)
y = df['class']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

print("Data cleaned successfully")
print("X_Training&Testing shape:",X_train.shape,X_test.shape)
print("y_Testing&Testing shape:",y_train.shape,y_test.shape)

"""**STEP 2 ‚Äì Train the XGBoost Classifier**"""

xgb_model = XGBClassifier(n_estimators=300,learning_rate=0.05,max_depth=6,random_state=42,subsample=0.9,colsample_bytree=0.8,scale_pos_weight=3,eval_metrics = 'logloss')

xgb_model.fit(X_train,y_train)

y_pred = xgb_model.predict(X_test)

print("XGBoost Classifier Results")
print("Accuracy:",round(accuracy_score(y_test,y_pred)*100,2),"%")
print("classification_report:",classification_report(y_test,y_pred))

cm = confusion_matrix(y_test,y_pred)
cm

"""**Why XGBoost?**

Uses gradient boosting for accuracy

Handles imbalance and missing values automatically

Fast and powerful for structured data

**STEP 3 ‚Äì Confusion Matrix Visualization**
"""

plt.figure(figsize=(5,4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Purples')
plt.title("XGBoost - Confusion Matrix")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.show()

"""**STEP 4 ‚Äì ROC Curve & AUC Score**"""

y_prob = xgb_model.predict_proba(X_test)[:, 1]
fpr, tpr, thresholds = roc_curve(y_test, y_prob)
auc_score = roc_auc_score(y_test, y_prob)

plt.figure(figsize=(6,5))
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f"ROC Curve (AUC = {auc_score:.2f})")
plt.plot([0,1], [0,1], color='navy', linestyle='--')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve - XGBoost Classifier")
plt.legend(loc="lower right")
plt.show()

print("AUC Score:", round(auc_score, 3))

"""**Interpretation:**

AUC close to 1.0 ‚Üí excellent model

AUC between 0.85‚Äì0.95 = high-quality predictions

**STEP 5 ‚Äì Feature Importance Visualization**
"""

importances = pd.Series(xgb_model.feature_importances_, index=X.columns).sort_values(ascending=True)

plt.figure(figsize=(8,5))
sns.barplot(x=importances, y=importances.index, palette='magma')
plt.title("Feature Importance - XGBoost Classifier")
plt.xlabel("Importance Score")
plt.ylabel("Features")
plt.show()

"""**Interpretation:**

Top features like industrial_risk, management_risk, and financial_flexibility
are the main drivers for bankruptcy prediction.

** STEP 6 ‚Äì Model Summary Dashboard**
"""

plt.figure(figsize=(14,8))

# Confusion Matrix
plt.subplot(2,2,1)
sns.heatmap(cm, annot=True, fmt='d', cmap='Purples')
plt.title("Confusion Matrix")

# Feature Importance
plt.subplot(2,2,2)
sns.barplot(x=importances, y=importances.index, palette='magma')
plt.title("Feature Importance")

# ROC Curve
plt.subplot(2,2,3)
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f"AUC = {auc_score:.2f}")
plt.plot([0,1],[0,1],'--',color='gray')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend()

# Summary Text
plt.subplot(2,2,4)
plt.text(0.1,0.7,f"Accuracy: {round(accuracy_score(y_test, y_pred)*100,2)}%", fontsize=13)
plt.text(0.1,0.6,f"AUC Score: {auc_score:.2f}", fontsize=13)
plt.text(0.1,0.5,f"Top Feature: {importances.idxmax()}", fontsize=13)
plt.axis('off')
plt.title("Model Summary")

plt.tight_layout()
plt.show()

"""**STEP 7 ‚Äì (Optional) SHAP Explainability Visualization**

SHAP explains how each feature affects each prediction ‚Äî perfect for explaining model decisions.
"""

import shap

# Initialize SHAP
explainer = shap.Explainer(xgb_model, X_test)
shap_values = explainer(X_test)

# Summary plot (feature influence)
shap.summary_plot(shap_values, X_test, plot_type="bar")

# Detailed beeswarm plot
shap.summary_plot(shap_values, X_test)



"""#Model-6 : Gradient Boosting Classifier (Sklearn)

**STEP 1 ‚Äì Import & Clean Dataset**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.ensemble import GradientBoostingClassifier

# Load dataset
df = pd.read_excel("/content/Bankruptcy (2).xlsx")

df.columns = df.columns.str.strip().str.lower()

#Encode target
df['class'] = df['class'].replace({'non-bankruptcy': 0,'non_bankruptcy': 0,'bankruptcy': 1,'bankrupt': 1})

# convert features to numeric
for col in df.columns:
    df[col]=pd.to_numeric(df[col],errors='coerce')

# Fill the missing numeric data with median
df = df.fillna(df.median())

# split the features & target
X = df.drop('class',axis=1)
y = df['class']

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)

print("Data cleaned successfully")
print("X_Training&Testing shape:",X_train.shape,X_test.shape)
print("y_Testing&Testing shape:",y_train.shape,y_test.shape)

"""**STEP 2 ‚Äì Train the Gradient Boosting Classifier**"""

gb_model = GradientBoostingClassifier(n_estimators=300,learning_rate=0.05,max_depth=3,random_state=42)

gb_model = GradientBoostingClassifier()

gb_model.fit(X_train,y_train)

y_pred = gb_model.predict(X_test)

print("Gradient Boosting Classifier Results")
print("Accuracy:",round(accuracy_score(y_test,y_pred)*100,2),"%")
print("classification Report:",y_test,y_pred)

cm = confusion_matrix(y_test,y_pred)
cm

"""**Why Gradient Boosting?**

Combines multiple weak decision trees into a strong ensemble

Excellent accuracy on smaller datasets

Naturally handles non-linear relationships

**STEP 3 ‚Äì Confusion Matrix Visualization**
"""

plt.figure(figsize=(5,4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Oranges')
plt.title("Gradient Boosting - Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

"""**STEP 4 ‚Äì ROC Curve & AUC Score**"""

y_prob = gb_model.predict_proba(X_test)[:, 1]
fpr, tpr, thresholds = roc_curve(y_test, y_prob)
auc_score = roc_auc_score(y_test, y_prob)

plt.figure(figsize=(6,5))
plt.plot(fpr, tpr, color='darkred', lw=2, label=f"ROC Curve (AUC = {auc_score:.2f})")
plt.plot([0,1], [0,1], color='navy', linestyle='--')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve - Gradient Boosting Classifier")
plt.legend(loc="lower right")
plt.show()

print("AUC Score:", round(auc_score, 3))

"""AUC > 0.85 ‚Üí Excellent classifier
Indicates how well the model separates bankruptcy from non-bankruptcy cases.

**STEP 5 ‚Äì Feature Importance Visualization**
"""

importances = pd.Series(gb_model.feature_importances_, index=X.columns).sort_values(ascending=True)

plt.figure(figsize=(8,5))
sns.barplot(x=importances, y=importances.index, palette='autumn')
plt.title("Feature Importance - Gradient Boosting Classifier")
plt.xlabel("Importance Score")
plt.ylabel("Features")
plt.show()

"""**Interpretation:**

Top bars represent features that contribute the most (like industrial_risk or financial_flexibility).

**STEP 6 ‚Äì Model Summary Dashboard**
"""

plt.figure(figsize=(14,8))

# Confusion Matrix
plt.subplot(2,2,1)
sns.heatmap(cm, annot=True, fmt='d', cmap='Oranges')
plt.title("Confusion Matrix")

# Feature Importance
plt.subplot(2,2,2)
sns.barplot(x=importances, y=importances.index, palette='autumn')
plt.title("Feature Importance")

# ROC Curve
plt.subplot(2,2,3)
plt.plot(fpr, tpr, color='darkred', lw=2, label=f"AUC = {auc_score:.2f}")
plt.plot([0,1],[0,1],'--',color='gray')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend()

# Summary
plt.subplot(2,2,4)
plt.text(0.1,0.7,f"Accuracy: {round(accuracy_score(y_test, y_pred)*100,2)}%", fontsize=13)
plt.text(0.1,0.6,f"AUC Score: {auc_score:.2f}", fontsize=13)
plt.text(0.1,0.5,f"Top Feature: {importances.idxmax()}", fontsize=13)
plt.axis('off')
plt.title("Model Summary")

plt.tight_layout()
plt.show()

from sklearn.metrics import accuracy_score

models = {
    'Logistic Regression': log_model,
    'Decision Tree': dt_model,
    'Random Forest': rf_model,
    'SVM': svm_model,
    'XGBoost': xgb_model,
    'Gradient Boosting': gb_model
}

acc_scores = []
for name, model in models.items():
    y_pred = model.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    acc_scores.append((name, acc))

acc_df = pd.DataFrame(acc_scores, columns=['Model','Accuracy']).sort_values(by='Accuracy', ascending=False)

plt.figure(figsize=(7,4))
sns.barplot(x='Model', y='Accuracy', data=acc_df, palette='coolwarm')
plt.title("Model Comparison - Accuracy")
plt.ylim(0,1)
plt.show()

print(acc_df)

from sklearn.metrics import accuracy_score

models = {
    'Logistic Regression': log_model,
    'Decision Tree': dt_model,
    'Random Forest': rf_model,
    'SVM': svm_model,
    'XGBoost': xgb_model,
    'Gradient Boosting': gb_model
}

acc_scores = []
for name, model in models.items():
    y_pred = model.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    acc_scores.append((name, acc))

acc_df = pd.DataFrame(acc_scores, columns=['Model','Accuracy']).sort_values(by='Accuracy', ascending=False)

plt.figure(figsize=(7,4))
plt.pie(acc_df['Accuracy'], labels=acc_df['Model'], autopct='%1.1f%%', startangle=90, colors=sns.color_palette('coolwarm', len(acc_df)))
plt.title("Model Comparison - Accuracy")
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
plt.show()

print(acc_df)



"""##5. Deployment & Testing :
**Week 4:-**
Build and test Streamlit/Flask app; integrate best model.

**Logistic Regression Model Training Code**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve

df = pd.read_excel("/content/Bankruptcy .xlsx")

df.columns = df.columns.str.strip().str.lower()

df["class"] = df["class"].replace({'non-bankruptcy': 0,'non_bankruptcy': 0,'bankruptcy': 1,'bankrupt': 1 })

for col in df.columns:
    df[col] = pd.to_numeric(df[col], errors='coerce')

df = df.dropna(subset=['class'])
df = df.fillna(df.median())

df.head()

X = df.drop('class', axis=1)
y = df['class']

X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42, stratify=y)

print(f"Training Data Shape: {X_train.shape}")
print(f"Testing Data Shape: {X_test.shape}")

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

log_model = LogisticRegression(random_state=42, solver='liblinear')

log_model.fit(X_train_scaled, y_train)

y_pred = log_model.predict(X_test_scaled)
y_prob = log_model.predict_proba(X_test_scaled)[:, 1]

import joblib
joblib.dump(log_model, "logistic_regression_model.pkl")
joblib.dump(scaler, "scaler.pkl")

pip install streamlit joblib scikit-learn pandas numpy

import streamlit as st

model = joblib.load("logistic_regression_model.pkl")

model

scaler = joblib.load("scaler.pkl")

st.set_page_config(page_title="Bankruptcy Prediction App", page_icon="üíº")
st.title("üíº Bankruptcy Prevention Prediction System")
st.write("""
This app predicts whether a company is likely to go **Bankrupt (1)** or **Non-Bankrupt (0)**
based on key financial and management risk indicators.
""")

st.sidebar.header("üìä Enter Company Risk Values (0 = Low, 0.5 = Medium, 1 = High)")

industrial_risk = st.sidebar.slider("Industrial Risk", 0.0, 1.0, 0.5)
management_risk = st.sidebar.slider("Management Risk", 0.0, 1.0, 0.5)
financial_flexibility = st.sidebar.slider("Financial Flexibility", 0.0, 1.0, 0.5)
credibility = st.sidebar.slider("Credibility", 0.0, 1.0, 0.5)
competitiveness = st.sidebar.slider("Competitiveness", 0.0, 1.0, 0.5)
operating_risk = st.sidebar.slider("Operating Risk", 0.0, 1.0, 0.5)

input_data = np.array([[industrial_risk, management_risk, financial_flexibility,
                        credibility, competitiveness, operating_risk]])

if st.sidebar.button("üîç Predict Bankruptcy"):
    # Scale the input data
    input_scaled = scaler.transform(input_data)

    # Predict class and probability
    prediction = model.predict(input_scaled)[0]
    probability = model.predict_proba(input_scaled)[0][1]

    st.subheader("üß† Prediction Results")
    if prediction == 1:
        st.error(f"‚ö†Ô∏è Bankruptcy Likely ‚Äî Probability: {probability:.2f}")
    else:
        st.success(f"‚úÖ Non-Bankruptcy ‚Äî Probability: {probability:.2f}")

    # Confidence gauge
    st.progress(float(probability))

    # Display input summary
    st.write("### üìã Input Summary")

    summary = {
        "Industrial Risk": industrial_risk,
        "Management Risk": management_risk,
        "Financial Flexibility": financial_flexibility,
        "Credibility": credibility,
        "Competitiveness": competitiveness,
        "Operating Risk": operating_risk
    }
    st.table(pd.DataFrame(summary.items(), columns=["Feature", "Value"]))
    st.markdown("""
---
*Model: Logistic Regression*
*Built using: Scikit-learn, Pandas, Streamlit*
*Project: Bankruptcy Prevention System*
""")

!wget -q -O - ipv4.icanhazip.com

!streamlit run  P588 & Bankruptcy Prevention_yogi.py & npx localtunnel --port 8501



!pip install python-pptx

from pptx import Presentation
from pptx.util import Inches, Pt
from pptx.dml.color import RGBColor
from pptx.enum.text import PP_ALIGN
from pptx.chart.data import CategoryChartData
from pptx.enum.chart import XL_CHART_TYPE

prs = Presentation()
blue = RGBColor(0, 70, 140)

def add_slide(title, content):
    slide = prs.slides.add_slide(prs.slide_layouts[1])
    slide.shapes.title.text = title
    body = slide.placeholders[1]
    body.text = content
    for p in body.text_frame.paragraphs:
        p.font.size = Pt(18)
        p.font.color.rgb = blue

# Title Slide
slide = prs.slides.add_slide(prs.slide_layouts[0])
slide.shapes.title.text = "Bankruptcy Prevention Using Machine Learning"
slide.placeholders[1].text = "By: Middi Yoganandareddy\nInstitute: ExcelR"

# Slides
add_slide("Problem Statement & Objective",
           "Predict company bankruptcy using key financial and operational risks.\n\n"
           "Objectives:\n‚Ä¢ Analyze risk indicators\n‚Ä¢ Build ML models\n‚Ä¢ Deploy best performer")
add_slide("Dataset Overview",
           "‚Ä¢ 250 companies, 6 financial risk factors\n"
           "‚Ä¢ Target: Bankruptcy (1) / Non-Bankruptcy (0)")
add_slide("Exploratory Data Analysis (EDA)",
           "‚Ä¢ Balanced dataset\n‚Ä¢ Industrial & Management Risk correlated with bankruptcy\n"
           "‚Ä¢ Credibility & Flexibility reduce bankruptcy likelihood")
add_slide("Data Preprocessing",
           "‚Ä¢ Encoded target variable\n‚Ä¢ Median imputation for missing values\n"
           "‚Ä¢ StandardScaler normalization\n‚Ä¢ 80/20 train-test split")
add_slide("Models Implemented",
           "1Ô∏è‚É£ Logistic Regression\n2Ô∏è‚É£ Decision Tree\n3Ô∏è‚É£ Random Forest\n4Ô∏è‚É£ SVM\n5Ô∏è‚É£ XGBoost (Best Performer)")

# Model accuracy chart
slide = prs.slides.add_slide(prs.slide_layouts[5])
slide.shapes.title.text = "Model Accuracy Comparison"
data = CategoryChartData()
data.categories = ["Logistic", "Decision Tree", "Random Forest", "SVM", "XGBoost"]
data.add_series("Accuracy (%)", (88, 84, 91, 90, 93))
prs.slides[-1].shapes.add_chart(XL_CHART_TYPE.COLUMN_CLUSTERED,
                                Inches(1), Inches(1.5), Inches(8), Inches(4), data)

add_slide("Best Model: XGBoost Classifier",
           "‚Ä¢ Accuracy 93 %, AUC 0.95\n‚Ä¢ Handles class imbalance well\n‚Ä¢ Boosting reduces overfitting\n"
           "Top features: Industrial Risk, Management Risk, Financial Flexibility")

# Feature-importance chart
slide = prs.slides.add_slide(prs.slide_layouts[5])
slide.shapes.title.text = "Feature Importance ‚Äì XGBoost"
data = CategoryChartData()
data.categories = ["Industrial Risk","Management Risk","Financial Flexibility",
                   "Credibility","Competitiveness","Operating Risk"]
data.add_series("Importance Score", (0.35,0.25,0.20,0.10,0.05,0.05))
prs.slides[-1].shapes.add_chart(XL_CHART_TYPE.BAR_CLUSTERED,
                                Inches(1), Inches(1.5), Inches(8), Inches(4), data)

add_slide("Streamlit Deployment",
           "‚Ä¢ Interactive web app for real-time prediction\n"
           "‚Ä¢ Inputs 0‚Äì1 risk levels ‚Üí Predict Bankruptcy/Non-Bankruptcy\n"
           "‚Ä¢ Tech stack: Streamlit, Scikit-learn, Joblib, Python")
add_slide("Results & Insights",
           "‚úÖ Best Model: XGBoost (93 %)\n‚úÖ Key Predictors: Industrial & Management Risk\n"
           "‚úÖ Streamlit app deployed for real-time predictions")
add_slide("Conclusion & Future Scope",
           "‚Ä¢ Accurate ML model for bankruptcy prediction\n"
           "‚Ä¢ Integrate live financial data APIs\n"
           "‚Ä¢ Develop predictive dashboards for decision makers")
add_slide("Thank You!",
           "Project by: Middi Yoganandareddy | ExcelR\n"
           "üìß [Your Email Here]\nüíº Streamlit App for Live Predictions")

prs.save("Bankruptcy_Prevention_Project_MiddiYoganandareddy.pptx")
print("‚úÖ PPT created! Check the file explorer to download.")

from pptx import Presentation
from pptx.util import Inches, Pt
from pptx.dml.color import RGBColor
from pptx.enum.text import PP_ALIGN
from pptx.chart.data import CategoryChartData
from pptx.enum.chart import XL_CHART_TYPE

# Create Presentation
prs = Presentation()
blue = RGBColor(0, 51, 153)
light_blue = RGBColor(200, 220, 255)

# Title Slide
slide = prs.slides.add_slide(prs.slide_layouts[0])
slide.shapes.title.text = "Bankruptcy Prevention Using Machine Learning"
slide.placeholders[1].text = "By: Middi Yoganandareddy\nInstitute: ExcelR"

# Function to add content slides
def add_slide(title, content):
    slide = prs.slides.add_slide(prs.slide_layouts[1])
    slide.shapes.title.text = title
    tf = slide.placeholders[1].text_frame
    tf.text = content
    for p in tf.paragraphs:
        p.font.size = Pt(18)
        p.font.color.rgb = blue

# Slide 2 - Problem Statement
add_slide("Problem Statement & Objective",
    "Goal: Predict whether a company is likely to go bankrupt using key financial and operational indicators.\n\n"
    "Objectives:\n‚Ä¢ Perform data analysis and visualization\n‚Ä¢ Train multiple ML models\n‚Ä¢ Select the best model (XGBoost)\n‚Ä¢ Deploy model with Streamlit")

# Slide 3 - Dataset Overview
add_slide("Dataset Overview",
    "‚Ä¢ Dataset: 250 companies\n‚Ä¢ 6 Features:\n  Industrial Risk, Management Risk, Financial Flexibility,\n  Credibility, Competitiveness, Operating Risk\n‚Ä¢ Target: Bankruptcy (1) or Non-Bankruptcy (0)")

# Slide 4 - EDA Summary
add_slide("Exploratory Data Analysis (EDA)",
    "‚Ä¢ Checked data balance and missing values\n‚Ä¢ Industrial & Management Risk correlated with bankruptcy\n‚Ä¢ Credibility and Flexibility lower bankruptcy chances\n‚Ä¢ Outliers handled with scaling")

# Slide 5 - Data Preprocessing
add_slide("Data Preprocessing Steps",
    "‚Ä¢ Encoded categorical values\n‚Ä¢ Imputed missing values (median)\n‚Ä¢ Scaled data using StandardScaler\n‚Ä¢ Train-Test Split: 80-20")

# Slide 6 - ML Models Implemented
add_slide("Machine Learning Models Implemented",
    "1Ô∏è‚É£ Logistic Regression\n2Ô∏è‚É£ Decision Tree Classifier\n3Ô∏è‚É£ Random Forest Classifier\n4Ô∏è‚É£ Support Vector Machine (SVM)\n5Ô∏è‚É£ XGBoost Classifier (Best Performer)")

# Slide 7 - Model Accuracy Chart
slide = prs.slides.add_slide(prs.slide_layouts[5])
slide.shapes.title.text = "Model Accuracy Comparison"
chart_data = CategoryChartData()
chart_data.categories = ["Logistic", "Decision Tree", "Random Forest", "SVM", "XGBoost"]
chart_data.add_series("Accuracy (%)", (88, 84, 91, 90, 93))
slide.shapes.add_chart(XL_CHART_TYPE.COLUMN_CLUSTERED,
                       Inches(1), Inches(1.5), Inches(8), Inches(4), chart_data)

# Slide 8 - XGBoost Model
add_slide("Best Model: XGBoost Classifier",
    "‚Ä¢ Accuracy: 93%, AUC: 0.95\n‚Ä¢ Handles imbalance efficiently\n‚Ä¢ Feature importance visualization shows top risk factors\n‚Ä¢ Most important: Industrial Risk, Management Risk, Financial Flexibility")

# Slide 9 - Feature Importance Chart
slide = prs.slides.add_slide(prs.slide_layouts[5])
slide.shapes.title.text = "Feature Importance ‚Äì XGBoost"
chart_data = CategoryChartData()
chart_data.categories = ["Industrial Risk", "Management Risk", "Financial Flexibility",
                         "Credibility", "Competitiveness", "Operating Risk"]
chart_data.add_series("Importance Score", (0.35, 0.25, 0.20, 0.10, 0.05, 0.05))
slide.shapes.add_chart(XL_CHART_TYPE.BAR_CLUSTERED,
                       Inches(1), Inches(1.5), Inches(8), Inches(4), chart_data)

# Slide 10 - Deployment
add_slide("Streamlit Model Deployment",
    "‚Ä¢ Web-based interactive prediction app\n‚Ä¢ Inputs: Risk values (0‚Äì1 sliders)\n‚Ä¢ Output: Bankruptcy / Non-Bankruptcy + Probability\n‚Ä¢ Tech stack: Streamlit, Joblib, Python, Scikit-learn")

# Slide 11 - Results & Insights
add_slide("Results & Insights",
    "‚úÖ XGBoost achieved 93% accuracy and AUC 0.95\n"
    "‚úÖ Industrial & Management Risk are key bankruptcy indicators\n"
    "‚úÖ Financial Flexibility reduces risk significantly\n"
    "‚úÖ Streamlit app ensures real-time usability")

# Slide 12 - Conclusion & Future Scope
add_slide("Conclusion & Future Scope",
    "‚Ä¢ Built robust ML pipeline for bankruptcy prevention\n"
    "‚Ä¢ Deployed live model via Streamlit\n"
    "‚Ä¢ Can integrate with live company data\n"
    "‚Ä¢ Future: Predictive dashboards, deep learning models")

# Slide 13 - Thank You
add_slide("Thank You!",
    "Project: Bankruptcy Prevention Using Machine Learning\n"
    "By: Middi Yoganandareddy | ExcelR\n"
    "üìß [Your Email Here]")

prs.save("Bankruptcy_Prevention_Presentation.pptx")
print("‚úÖ PPT created! Check the file explorer to download.")

